/**
 * Ultimate Code Tokenizer - çœŸæ­£å¯¦ç”¨å˜… StarCoder2 + æœç´¢å„ªåŒ–æ•´åˆ
 * çµåˆ StarCoder2 å˜…å¼·å¤§ä»£ç¢¼ç†è§£èƒ½åŠ›åŒå¯¦éš›æœç´¢éœ€æ±‚
 */

import { AutoTokenizer } from '@huggingface/transformers';
import { ProfessionalTokenizer } from './professional-tokenizer.js';

export interface UltimateToken {
  text: string;
  starcoderId?: number;
  starcoderScore: number; // StarCoder2 ç½®ä¿¡åº¦
  professionalScore: number; // åŸæœ‰åˆ†æ•¸
  finalScore: number; // æœ€çµ‚åˆ†æ•¸
  confidence: number;
  relevance: 'high' | 'medium' | 'low';
  source: 'starcoder' | 'professional' | 'both';
}

export interface UltimateResult {
  tokens: UltimateToken[];
  metadata: {
    totalTokens: number;
    starcoderTokens: number;
    professionalTokens: number;
    processingTime: number;
    averageScore: number;
  };
  starcoder: {
    available: boolean;
    decodedText: string;
    tokenCount: number;
  };
}

/**
 * Ultimate Code Tokenizer - çœŸæ­£å¯¦ç”¨å˜…æ•´åˆæ–¹æ¡ˆ
 */
export class UltimateCodeTokenizer {
  private starcoderTokenizer: any;
  private professionalTokenizer: ProfessionalTokenizer;
  private initialized: boolean = false;
  private options: {
    starcoderModelPath: string;
    starcoderWeight: number;
    professionalWeight: number;
    enableStarcoder: boolean;
  };

  constructor(options: {
    starcoderModelPath?: string;
    starcoderWeight?: number;
    professionalWeight?: number;
    enableStarcoder?: boolean;
  } = {}) {
    this.options = {
      starcoderModelPath: options.starcoderModelPath || './models/starcoder2',
      starcoderWeight: options.starcoderWeight || 0.7,
      professionalWeight: options.professionalWeight || 0.3,
      enableStarcoder: options.enableStarcoder !== false
    };

    this.professionalTokenizer = new ProfessionalTokenizer({
      codeAware: true,
      extractTechnicalTerms: true,
      useNgrams: true,
      extractCompoundWords: true,
      useContextualScoring: true,
    });
  }

  /**
   * åˆå§‹åŒ–
   */
  async initialize(): Promise<void> {
    if (this.initialized) return;

    console.log('ğŸš€ Initializing Ultimate Code Tokenizer...');

    // åˆå§‹åŒ– StarCoder2 (å¦‚æœå•Ÿç”¨)
    if (this.options.enableStarcoder) {
      try {
        console.log('ğŸ¤– Loading StarCoder2 tokenizer...');
        this.starcoderTokenizer = await AutoTokenizer.from_pretrained(this.options.starcoderModelPath);
        console.log('âœ… StarCoder2 loaded successfully');
      } catch (error) {
        console.warn('âš ï¸  StarCoder2 loading failed, using ProfessionalTokenizer only:', error.message);
        this.options.enableStarcoder = false;
      }
    }

    this.initialized = true;
    console.log('ğŸ‰ Ultimate Code Tokenizer initialized successfully!');
  }

  /**
   * ä¸»è¦ tokenization æ–¹æ³•
   */
  async tokenize(content: string): Promise<UltimateResult> {
    if (!this.initialized) {
      await this.initialize();
    }

    const startTime = Date.now();
    console.log('ğŸ”¤ Starting ultimate tokenization...');

    let starcoderResult: any = null;
    let professionalTokens = [];

    // ä¸¦è¡Œè™•ç†
    const promises = [
      this.processWithProfessional(content)
    ];

    if (this.options.enableStarcoder) {
      promises.push(this.processWithStarCoder(content));
    }

    const [professional, starcoder] = await Promise.all(promises);
    professionalTokens = professional;
    starcoderResult = starcoder;

    // èåˆçµæœ
    const ultimateTokens = this.mergeResults(professionalTokens, starcoderResult, content);

    const processingTime = Date.now() - startTime;
    console.log(`âœ… Ultimate tokenization completed in ${processingTime}ms`);

    return {
      tokens: ultimateTokens,
      metadata: {
        totalTokens: ultimateTokens.length,
        starcoderTokens: starcoderResult ? starcoderResult.tokenCount : 0,
        professionalTokens: professionalTokens.length,
        processingTime,
        averageScore: this.calculateAverageScore(ultimateTokens)
      },
      starcoder: {
        available: this.options.enableStarcoder && starcoderResult !== null,
        decodedText: starcoderResult?.decodedText || '',
        tokenCount: starcoderResult?.tokenCount || 0
      }
    };
  }

  /**
   * ä½¿ç”¨ ProfessionalTokenizer è™•ç†
   */
  private async processWithProfessional(content: string) {
    return this.professionalTokenizer.tokenize(content);
  }

  /**
   * ä½¿ç”¨ StarCoder2 è™•ç†
   */
  private async processWithStarCoder(content: string) {
    if (!this.starcoderTokenizer) return null;

    try {
      const encoded = await this.starcoderTokenizer(content);
      const inputIds = encoded.input_ids.tolist()[0];
      const decodedText = await this.starcoderTokenizer.decode(inputIds);

      return {
        inputIds,
        decodedText,
        tokenCount: inputIds.length
      };
    } catch (error) {
      console.warn('StarCoder2 processing failed:', error.message);
      return null;
    }
  }

  /**
   * èåˆå…©ç¨® tokenizer çš„çµæœ
   */
  private mergeResults(
    professionalTokens: any[],
    starcoderResult: any,
    originalContent: string
  ): UltimateToken[] {
    const ultimateTokens: UltimateToken[] = [];

    // 1. é¦–å…ˆè™•ç† ProfessionalTokenizer çš„çµæœ
    for (const profToken of professionalTokens) {
      const ultimateToken: UltimateToken = {
        text: profToken.text,
        professionalScore: profToken.score,
        starcoderScore: this.options.enableStarcoder ? 0.8 : 0, // é»˜èªé«˜ç½®ä¿¡åº¦
        finalScore: profToken.score * this.options.professionalWeight,
        confidence: profToken.score,
        relevance: this.determineRelevance(profToken.score),
        source: 'professional'
      };

      // å¦‚æœæœ‰ StarCoder2ï¼Œå˜—è©¦æ‰¾åˆ°å°æ‡‰
      if (starcoderResult && starcoderResult.decodedText) {
        const matchScore = this.calculateMatchScore(profToken.text, starcoderResult.decodedText);
        ultimateToken.starcoderScore = matchScore;
        ultimateToken.finalScore = (
          profToken.score * this.options.professionalWeight +
          matchScore * this.options.starcoderWeight
        );
        ultimateToken.source = matchScore > 0.5 ? 'both' : 'professional';
      }

      ultimateTokens.push(ultimateToken);
    }

    // 2. å¦‚æœå•Ÿç”¨ StarCoder2ï¼Œæ·»åŠ ç¨ç‰¹å˜… tokens
    if (starcoderResult && this.options.enableStarcoder) {
      const uniqueStarTokens = this.extractUniqueTokens(starcoderResult, professionalTokens);
      for (const starToken of uniqueStarTokens) {
        const ultimateToken: UltimateToken = {
          text: starToken.text,
          professionalScore: 0.3, // çµ¦å€‹åŸºç¤åˆ†æ•¸
          starcoderScore: 0.9,
          finalScore: 0.9 * this.options.starcoderWeight + 0.3 * this.options.professionalWeight,
          confidence: 0.8,
          relevance: 'medium',
          source: 'starcoder'
        };
        ultimateTokens.push(ultimateToken);
      }
    }

    // 3. å»é‡ã€æ’åºã€éæ¿¾
    const uniqueTokens = this.deduplicateTokens(ultimateTokens);
    const filteredTokens = uniqueTokens.filter(token => token.finalScore > 0.2);
    const sortedTokens = filteredTokens.sort((a, b) => b.finalScore - a.finalScore);

    return sortedTokens;
  }

  /**
   * è¨ˆç®—åŒ¹é…åˆ†æ•¸
   */
  private calculateMatchScore(profTokenText: string, decodedText: string): number {
    const lowerProfToken = profTokenText.toLowerCase();
    const lowerDecoded = decodedText.toLowerCase();

    // ç²¾ç¢ºåŒ¹é…
    if (lowerDecoded.includes(lowerProfToken)) return 1.0;

    // éƒ¨åˆ†åŒ¹é…
    const profWords = lowerProfToken.split(/\s+/);
    let matchCount = 0;
    for (const word of profWords) {
      if (lowerDecoded.includes(word)) matchCount++;
    }

    if (matchCount > 0) {
      return matchCount / profWords.length;
    }

    // å­—ç¬¦ç´šåˆ¥åŒ¹é…
    let charMatches = 0;
    for (const char of lowerProfToken) {
      if (lowerDecoded.includes(char)) charMatches++;
    }

    return charMatches / lowerProfToken.length * 0.3;
  }

  /**
   * æå– StarCoder2 ç¨ç‰¹å˜… tokens
   */
  private extractUniqueTokens(starcoderResult: any, professionalTokens: any[]): { text: string; id: number }[] {
    const profTokenTexts = new Set(professionalTokens.map(t => t.text.toLowerCase()));
    const uniqueTokens: { text: string; id: number }[] = [];

    // å¾è§£ç¢¼æ–‡æœ¬ä¸­æå–è©å½™
    const words = starcoderResult.decodedText
      .toLowerCase()
      .split(/\s+/)
      .filter(word => word.length > 2 && !profTokenTexts.has(word));

    // ç‚ºæ¯å€‹ç¨ç‰¹è©å½™å‰µå»º token
    words.forEach((word, index) => {
      uniqueTokens.push({
        text: word,
        id: starcoderResult.inputIds[index] || index
      });
    });

    return uniqueTokens;
  }

  /**
   * å»é‡ tokens
   */
  private deduplicateTokens(tokens: UltimateToken[]): UltimateToken[] {
    const seen = new Set<string>();
    const unique: UltimateToken[] = [];

    for (const token of tokens) {
      const key = token.text.toLowerCase();
      if (!seen.has(key)) {
        seen.add(key);
        unique.push(token);
      } else {
        // å¦‚æœå·²å­˜åœ¨ï¼Œä¿ç•™åˆ†æ•¸æ›´é«˜å˜…ç‰ˆæœ¬
        const existingIndex = unique.findIndex(t => t.text.toLowerCase() === key);
        if (existingIndex >= 0 && token.finalScore > unique[existingIndex].finalScore) {
          unique[existingIndex] = token;
        }
      }
    }

    return unique;
  }

  /**
   * ç¢ºå®šç›¸é—œæ€§ç´šåˆ¥
   */
  private determineRelevance(score: number): 'high' | 'medium' | 'low' {
    if (score >= 0.8) return 'high';
    if (score >= 0.5) return 'medium';
    return 'low';
  }

  /**
   * è¨ˆç®—å¹³å‡åˆ†æ•¸
   */
  private calculateAverageScore(tokens: UltimateToken[]): number {
    if (tokens.length === 0) return 0;
    const totalScore = tokens.reduce((sum, token) => sum + token.finalScore, 0);
    return totalScore / tokens.length;
  }

  /**
   * ä¾¿åˆ©æ–¹æ³•ï¼šç²å–æœ€é«˜åˆ†æ•¸çš„ tokens
   */
  async getTopTokens(content: string, limit: number = 20): Promise<UltimateToken[]> {
    const result = await this.tokenize(content);
    return result.tokens.slice(0, limit);
  }

  /**
   * ä¾¿åˆ©æ–¹æ³•ï¼šç²å–æŠ€è¡“ç›¸é—œ tokens
   */
  async getTechnicalTokens(content: string): Promise<UltimateToken[]> {
    const result = await this.tokenize(content);
    return result.tokens.filter(token =>
      token.finalScore > 0.6 &&
      (token.text.match(/^[A-Z_]+$/) || // æŠ€è¡“è¡“èª
       token.text.match(/^[a-z]+[A-Z]/) || // camelCase
       token.text.length > 6) // é•·è©å½™
    );
  }

  /**
   * ä¾¿åˆ©æ–¹æ³•ï¼šæœç´¢ç‰¹å®šå…§å®¹
   */
  async searchTokens(content: string, pattern: RegExp): Promise<UltimateToken[]> {
    const result = await this.tokenize(content);
    return result.tokens.filter(token => pattern.test(token.text));
  }
}